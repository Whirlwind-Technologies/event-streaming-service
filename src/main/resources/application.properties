# Event Streaming Service Configuration
server.port=8085
server.servlet.context-path=/event-streaming

spring.application.name=event-streaming-service

# Kafka Configuration
spring.kafka.bootstrap-servers=${KAFKA_BROKERS:localhost:9092}
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=io.confluent.kafka.serializers.protobuf.KafkaProtobufSerializer
spring.kafka.producer.acks=all
spring.kafka.producer.properties.schema.registry.url=${SCHEMA_REGISTRY_URL:http://localhost:8081}

spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=io.confluent.kafka.serializers.protobuf.KafkaProtobufDeserializer
spring.kafka.consumer.group-id=event-streaming-service
spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.properties.schema.registry.url=${SCHEMA_REGISTRY_URL:http://localhost:8081}
# Fixed: specific.protobuf.value.type expects a class name, not boolean
spring.kafka.consumer.properties.specific.protobuf.value.type=com.google.protobuf.DynamicMessage

# Disable Kafka Streams (we're using regular producer/consumer)
spring.kafka.streams.auto-startup=false

# Redis Configuration
spring.data.redis.host=${REDIS_HOST:localhost}
spring.data.redis.port=${REDIS_PORT:6379}
spring.data.redis.database=5
spring.data.redis.timeout=5000

# Schema Registry
schema.registry.url=${SCHEMA_REGISTRY_URL:http://localhost:8081}
schema.registry.compatibility=FULL_TRANSITIVE

# Allow bean overriding (temporary fix)
spring.main.allow-bean-definition-overriding=false

# Actuator
management.endpoints.web.exposure.include=health,info,metrics,prometheus
management.endpoint.health.show-details=always

# Logging
logging.level.com.nnipa.eventstreaming=DEBUG
logging.level.org.apache.kafka=INFO